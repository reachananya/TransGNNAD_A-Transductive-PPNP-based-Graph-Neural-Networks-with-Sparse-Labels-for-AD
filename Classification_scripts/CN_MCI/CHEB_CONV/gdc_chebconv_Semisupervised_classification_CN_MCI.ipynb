{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Wt6aqRoAC7fDIaCxs4WXw7UtdxNmpplW","timestamp":1754124375613},{"file_id":"1OZL0M_Zh_cHw-H5utOpn6sc6NtsdViEf","timestamp":1747279993555},{"file_id":"1UDJaQxcixFBoLdBH8KoBHMxo19SRI1My","timestamp":1747238356883},{"file_id":"1y40jw9ksHpmIeKlcMcBmqpvK5gnOF8vb","timestamp":1746704120540},{"file_id":"1vLY-ZFYfdexWlCV5nMBy_s8I-TdUUtXi","timestamp":1746702771944},{"file_id":"1O03CrIGAL9R-y4SCrFZLyak5k2mxsJxe","timestamp":1741177807100}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mi6DYiF-SVHo","executionInfo":{"status":"ok","timestamp":1754124776877,"user_tz":-330,"elapsed":15692,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"5f970040-1b44-4691-d3e2-3e33ae383a1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Acknowledgment:\n","# This project benefits significantly from the insights in the GDC (Graph Diffusion Convolution) demo,\n","# authored by Johannes Klicpera. The notebook—available at\n","# https://github.com/gasteigerjo/gdc/blob/master/gdc_demo.ipynb\n","# —served as a valuable reference in developing our own implementation. Our sincere gratitude to the original author.\n"],"metadata":{"id":"pQGSJ_Q78nZi"}},{"cell_type":"code","source":["!pip install -q torch_geometric\n","!pip install -q class_resolver\n","!pip3 install pymatting\n","!pip install seaborn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Me9KNoq6NQzw","executionInfo":{"status":"ok","timestamp":1754207220737,"user_tz":-330,"elapsed":2616,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"dd6e7c98-1df9-467c-f267-5dd2a4045127"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Requirement already satisfied: pymatting in ./.local/lib/python3.10/site-packages (1.1.14)\n","Requirement already satisfied: numpy>=1.16.0 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from pymatting) (1.26.4)\n","Requirement already satisfied: pillow>=5.2.0 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from pymatting) (11.1.0)\n","Requirement already satisfied: numba!=0.49.0 in ./.local/lib/python3.10/site-packages (from pymatting) (0.61.2)\n","Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from pymatting) (1.11.4)\n","Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.local/lib/python3.10/site-packages (from numba!=0.49.0->pymatting) (0.44.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Requirement already satisfied: seaborn in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (0.13.2)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from seaborn) (1.26.4)\n","Requirement already satisfied: pandas>=1.2 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from seaborn) (2.3.0)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from seaborn) (3.10.3)\n","Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n","Requirement already satisfied: pillow>=8 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: six>=1.5 in ./anaconda3/envs/tmp_pyg118/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import scipy.sparse as sp\n","from collections import defaultdict\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GCNConv,GATConv,ChebConv\n","from tqdm import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, auc,roc_auc_score,roc_curve\n","import torch.nn as nn\n","from torch_geometric.utils import to_scipy_sparse_matrix\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt"],"metadata":{"id":"tv7boNsbNGuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","cn_fa_feature_path = \"/home/snu/Downloads/Histogram_feature_CN_FA_20bin.npy\"\n","mci_fa_feature_path = \"/home/snu/Downloads/Histogram_feature_MCI_FA_20bin.npy\"\n","\n","#cn_fa_feature_path = \"/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/ISBI_ADNI_CN_dataset/Processed_histogram_features_CN/Histogram_feature_CN_FA_20bin.npy\"\n","#mci_fa_feature_path = \"/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/ISBI_ADNI_MCI_dataset/Processed_histogram_features_MCI/Histogram_feature_MCI_FA_20bin.npy\"\n","cn_features_dict = np.load(cn_fa_feature_path, allow_pickle=True).item()\n","mci_features_dict = np.load(mci_fa_feature_path, allow_pickle=True).item()\n","\n","cn_features = np.array(list(cn_features_dict.values()))\n","mci_features = np.array(list(mci_features_dict.values()))\n","\n","cn_labels = np.zeros(cn_features.shape[0])\n","mci_labels = np.ones(mci_features.shape[0])\n","\n","X = np.vstack([cn_features, mci_features])\n","y = np.hstack([cn_labels, mci_labels])"],"metadata":{"id":"lY70a67PO5fK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = np.vstack([cn_features, mci_features])\n","y = np.hstack([cn_labels, mci_labels])\n","\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","num_nodes, num_feats = X.shape\n","print(f\"Features: {X.shape}, Labels: {y.shape}\")"],"metadata":{"id":"U36GtUurSabo","executionInfo":{"status":"ok","timestamp":1754380003244,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ff33eb5-77ae-40f4-da37-0315c32f918e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: (300, 180), Labels: (300,)\n"]}]},{"cell_type":"code","source":["X_tensor = torch.tensor(X, dtype=torch.float32)\n","y_tensor = torch.tensor(y, dtype=torch.long)"],"metadata":{"id":"UKUWQ0sXPMbC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpha = 0.1\n","X_norm = F.normalize(X_tensor, p=2, dim=1)\n","sim_matrix = torch.mm(X_norm, X_norm.T)\n","\n","src, dst = torch.where(sim_matrix > alpha)\n","mask = src != dst\n","src, dst = src[mask], dst[mask]\n","\n","self_loops = torch.arange(X_tensor.shape[0])\n","src = torch.cat([src, self_loops])\n","dst = torch.cat([dst, self_loops])\n","\n","edges = torch.stack([src, dst], dim=0)\n","edges_rev = torch.stack([dst, src], dim=0)\n","edge_index = torch.cat([edges, edges_rev], dim=1)\n","\n","edge_index = torch.unique(edge_index, dim=1)\n","\n","print(f\"Graph Nodes: {X_tensor.shape[0]}, Edges: {edge_index.shape[1]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSje7ZGJPRVw","executionInfo":{"status":"ok","timestamp":1754380005598,"user_tz":-330,"elapsed":59,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"78996779-4572-4ce2-af02-76b92a578b24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Graph Nodes: 300, Edges: 16508\n"]}]},{"cell_type":"code","source":["A = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes)"],"metadata":{"id":"Wq9uLyIlvZQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gdc(A: sp.csr_matrix, alpha: float, eps: float):\n","    N = A.shape[0]\n","\n","    # Self-loops\n","    A_loop = sp.eye(N) + A\n","\n","    # Symmetric transition matrix\n","    D_loop_vec = A_loop.sum(0).A1\n","    D_loop_vec_invsqrt = 1 / np.sqrt(D_loop_vec)\n","    D_loop_invsqrt = sp.diags(D_loop_vec_invsqrt)\n","    T_sym = D_loop_invsqrt @ A_loop @ D_loop_invsqrt\n","\n","    # PPR-based diffusion\n","    S = alpha * sp.linalg.inv(sp.eye(N) - (1 - alpha) * T_sym)\n","\n","    # Sparsify using threshold epsilon\n","    S_tilde = S.multiply(S >= eps)\n","\n","    # Column-normalized transition matrix on graph S_tilde\n","    D_tilde_vec = S_tilde.sum(0).A1\n","    T_S = S_tilde / D_tilde_vec\n","    return T_S"],"metadata":{"id":"83XlB7rX5-Fp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gdc_heat(A: sp.csr_matrix, t: float, eps: float):\n","    N = A.shape[0]\n","\n","    # Self-loops\n","    A_loop = sp.eye(N) + A\n","\n","    # Symmetric transition matrix\n","    D_loop_vec = A_loop.sum(0).A1\n","    D_loop_vec_invsqrt = 1 / np.sqrt(D_loop_vec)\n","    D_loop_invsqrt = sp.diags(D_loop_vec_invsqrt)\n","    T_sym = D_loop_invsqrt @ A_loop @ D_loop_invsqrt\n","\n","    # Heat-based diffusion\n","    S = sp.csr_matrix(expm(-t * (np.eye(N) - T_sym)))\n","    # Sparsify using threshold epsilon\n","    S_tilde = S.multiply(S >= eps)\n","\n","    # Column-normalized transition matrix on graph S_tilde\n","    D_tilde_vec = S_tilde.sum(0).A1\n","    T_S = S_tilde / D_tilde_vec\n","    return T_S"],"metadata":{"id":"z0KiFHme5EsP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_ppr_matrix(\n","        adj_matrix: np.ndarray,\n","        alpha: float = 0.1) -> np.ndarray:\n","    num_nodes = adj_matrix.shape[0]\n","    A_tilde = adj_matrix + np.eye(num_nodes)\n","    D_tilde = np.diag(1/np.sqrt(A_tilde.sum(axis=1)))\n","    H = D_tilde @ A_tilde @ D_tilde\n","    return alpha * np.linalg.inv(np.eye(num_nodes) - (1 - alpha) * H)"],"metadata":{"id":"P8Y0gUM93c1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.linalg import expm\n","def get_heat_matrix(\n","        adj_matrix: np.ndarray,\n","        t: float = 5.0) -> np.ndarray:\n","    num_nodes = adj_matrix.shape[0]\n","    A_tilde = adj_matrix + np.eye(num_nodes)\n","    D_tilde = np.diag(1/np.sqrt(A_tilde.sum(axis=1)))\n","    H = D_tilde @ A_tilde @ D_tilde\n","    return expm(-t * (np.eye(num_nodes) - H))"],"metadata":{"id":"0eAwMfVU3jMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def to_edge_index(A_sp):\n","    return torch.tensor(np.vstack(A_sp.nonzero()), dtype=torch.long)\n","\n","x_tensor = torch.tensor(X, dtype=torch.float).to(device)\n","y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n","\n","data_none = Data(x=x_tensor, edge_index=edge_index.to(device), y=y_tensor)\n","A_heat = gdc_heat(A, t=2.0, eps=0.1)\n","A_ppr = gdc(A, alpha=0.15, eps=0.1)\n","# A_heat = get_heat_matrix(A.toarray(),t=5.0)\n","# A_ppr = get_ppr_matrix(A.toarray(),alpha=0.05)\n","data_heat = Data(x=x_tensor, edge_index=to_edge_index(A_heat).to(device), y=y_tensor)\n","data_ppr = Data(x=x_tensor, edge_index=to_edge_index(A_ppr).to(device), y=y_tensor)"],"metadata":{"id":"mmSxhDyuSbIb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Cheb(torch.nn.Module):\n","    def __init__(self, in_dim, hidden_dim, out_dim, K=3, dropout=0.2):\n","        super().__init__()\n","        self.conv1 = ChebConv(in_dim, hidden_dim, K=K)\n","        self.conv2 = ChebConv(hidden_dim, out_dim, K=K)\n","        self.dropout = dropout\n","\n","    def reset_parameters(self):\n","        self.conv1.reset_parameters()\n","        self.conv2.reset_parameters()\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)"],"metadata":{"id":"6qhdCCRSShu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_datasets = {\n","    \"none\": data_none,\n","    \"heat\": data_heat,\n","    \"ppr\": data_ppr\n","}"],"metadata":{"id":"SijfZ0rq7IfJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","num_epochs = 5000\n","\n","for name, data in graph_datasets.items():\n","    print(f\"\\n\\n===== Running 20-Fold CV for {name.upper()} Graph =====\")\n","    accuracies, precisions, recalls, f1_scores, losses = [], [], [], [], []\n","    all_fpr, all_tpr, all_auc = [], [], []\n","    all_y_true, all_y_proba = [], []\n","\n","    data = data.to(device)\n","    num_feats = data.num_node_features\n","\n","    for fold, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n","        print(f\"\\nTraining fold {fold + 1} for {name} graph\")\n","\n","        train_mask = torch.tensor(train_idx, dtype=torch.long, device=device)\n","        test_mask  = torch.tensor(test_idx,  dtype=torch.long, device=device)\n","\n","        model = Cheb(num_feats, 512, 2, dropout=0.2).to(device)\n","        model.reset_parameters()\n","        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n","        loss_fn = nn.NLLLoss()\n","\n","\n","        for epoch in range(num_epochs):\n","            model.train()\n","            optimizer.zero_grad()\n","            out = model(data)\n","            loss = loss_fn(out[train_mask], y_tensor[train_mask])\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","        with torch.no_grad():\n","            logits    = model(data)\n","            y_pred = logits.argmax(dim=1).cpu().numpy()\n","            y_proba = torch.exp(logits).cpu().numpy()[:, 1]  # Probabilities for class 1\n","\n","        y_true_test = y_tensor[test_mask].cpu().numpy()\n","        y_pred_test = y_pred[test_mask.cpu().numpy()]\n","        y_proba_test = y_proba[test_mask.cpu().numpy()]\n","\n","        acc = accuracy_score(y_true_test, y_pred_test)\n","        prec = precision_score(y_true_test, y_pred_test)\n","        rec = recall_score(y_true_test, y_pred_test)\n","        f1 = f1_score(y_true_test, y_pred_test)\n","        ce_loss = log_loss(y_true_test, y_proba_test)\n","        auc = roc_auc_score(y_true_test, y_proba_test)\n","        fpr, tpr, _ = roc_curve(y_true_test, y_proba_test)\n","\n","\n","        accuracies.append(acc)\n","        precisions.append(prec)\n","        recalls.append(rec)\n","        f1_scores.append(f1)\n","        losses.append(ce_loss)\n","        all_auc.append(auc)\n","        all_fpr.append(fpr)\n","        all_tpr.append(tpr)\n","        all_y_true.extend(y_true_test)\n","        all_y_proba.extend(y_proba_test)\n","\n","        print(f\"Fold {fold + 1}: Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","              f\"F1={f1:.4f} | Loss={ce_loss:.4f} | AUC={auc:.4f}\")\n","\n","    # Final aggregated metrics with mean and std\n","    print(f\"\\n==== {name.upper()} Graph 20-Fold Average Results ====\")\n","    print(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","    print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","    print(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","    print(f\"F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","    print(f\"Cross-Entropy Loss: {np.mean(losses):.4f} ± {np.std(losses):.4f}\")\n","    print(f\"AUC: {np.mean(all_auc):.4f} ± {np.std(all_auc):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzhcv9g-BBjG","outputId":"09c17499-a4f9-41d4-d6ac-2b74d6c71a13","executionInfo":{"status":"ok","timestamp":1754382593251,"user_tz":-330,"elapsed":2499468,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","===== Running 20-Fold CV for NONE Graph =====\n","\n","Training fold 1 for none graph\n","Fold 1: Acc=0.7000 | Prec=0.6971 | Rec=0.8133 | F1=0.7508 | Loss=0.7142 | AUC=0.7726\n","\n","Training fold 2 for none graph\n","Fold 2: Acc=0.6852 | Prec=0.6879 | Rec=0.7933 | F1=0.7368 | Loss=0.7526 | AUC=0.7149\n","\n","Training fold 3 for none graph\n","Fold 3: Acc=0.6593 | Prec=0.6648 | Rec=0.7800 | F1=0.7178 | Loss=0.7714 | AUC=0.7234\n","\n","Training fold 4 for none graph\n","Fold 4: Acc=0.6741 | Prec=0.7348 | Rec=0.6467 | F1=0.6879 | Loss=0.6863 | AUC=0.7598\n","\n","Training fold 5 for none graph\n","Fold 5: Acc=0.7259 | Prec=0.7235 | Rec=0.8200 | F1=0.7688 | Loss=0.9080 | AUC=0.7364\n","\n","Training fold 6 for none graph\n","Fold 6: Acc=0.6630 | Prec=0.7153 | Rec=0.6533 | F1=0.6829 | Loss=0.8017 | AUC=0.7085\n","\n","Training fold 7 for none graph\n","Fold 7: Acc=0.7185 | Prec=0.7256 | Rec=0.7933 | F1=0.7580 | Loss=0.7036 | AUC=0.7645\n","\n","Training fold 8 for none graph\n","Fold 8: Acc=0.7259 | Prec=0.7135 | Rec=0.8467 | F1=0.7744 | Loss=0.6852 | AUC=0.7631\n","\n","Training fold 9 for none graph\n","Fold 9: Acc=0.6593 | Prec=0.6933 | Rec=0.6933 | F1=0.6933 | Loss=0.8433 | AUC=0.7150\n","\n","Training fold 10 for none graph\n","Fold 10: Acc=0.6630 | Prec=0.6832 | Rec=0.7333 | F1=0.7074 | Loss=0.7865 | AUC=0.7395\n","\n","Training fold 11 for none graph\n","Fold 11: Acc=0.7259 | Prec=0.7468 | Rec=0.7667 | F1=0.7566 | Loss=0.6422 | AUC=0.7848\n","\n","Training fold 12 for none graph\n","Fold 12: Acc=0.7259 | Prec=0.7468 | Rec=0.7667 | F1=0.7566 | Loss=0.7086 | AUC=0.7682\n","\n","Training fold 13 for none graph\n","Fold 13: Acc=0.7333 | Prec=0.7216 | Rec=0.8467 | F1=0.7791 | Loss=0.7819 | AUC=0.7620\n","\n","Training fold 14 for none graph\n","Fold 14: Acc=0.6667 | Prec=0.7206 | Rec=0.6533 | F1=0.6853 | Loss=0.8557 | AUC=0.7215\n","\n","Training fold 15 for none graph\n","Fold 15: Acc=0.7444 | Prec=0.7516 | Rec=0.8067 | F1=0.7781 | Loss=0.6553 | AUC=0.7967\n","\n","Training fold 16 for none graph\n","Fold 16: Acc=0.7741 | Prec=0.7697 | Rec=0.8467 | F1=0.8063 | Loss=0.6669 | AUC=0.7933\n","\n","Training fold 17 for none graph\n","Fold 17: Acc=0.6667 | Prec=0.6829 | Rec=0.7467 | F1=0.7134 | Loss=0.8453 | AUC=0.7182\n","\n","Training fold 18 for none graph\n","Fold 18: Acc=0.6704 | Prec=0.7133 | Rec=0.6800 | F1=0.6962 | Loss=0.7108 | AUC=0.7482\n","\n","Training fold 19 for none graph\n","Fold 19: Acc=0.6889 | Prec=0.6854 | Rec=0.8133 | F1=0.7439 | Loss=0.8357 | AUC=0.7251\n","\n","Training fold 20 for none graph\n","Fold 20: Acc=0.6963 | Prec=0.6932 | Rec=0.8133 | F1=0.7485 | Loss=0.7580 | AUC=0.7465\n","\n","==== NONE Graph 20-Fold Average Results ====\n","Accuracy: 0.6983 ± 0.0330\n","Precision: 0.7135 ± 0.0268\n","Recall: 0.7657 ± 0.0657\n","F1 Score: 0.7371 ± 0.0358\n","Cross-Entropy Loss: 0.7557 ± 0.0737\n","AUC: 0.7481 ± 0.0267\n","\n","\n","===== Running 20-Fold CV for HEAT Graph =====\n","\n","Training fold 1 for heat graph\n","Fold 1: Acc=0.7333 | Prec=0.7600 | Rec=0.7600 | F1=0.7600 | Loss=0.7664 | AUC=0.7889\n","\n","Training fold 2 for heat graph\n","Fold 2: Acc=0.7185 | Prec=0.7534 | Rec=0.7333 | F1=0.7432 | Loss=0.7551 | AUC=0.7641\n","\n","Training fold 3 for heat graph\n","Fold 3: Acc=0.6852 | Prec=0.7124 | Rec=0.7267 | F1=0.7195 | Loss=0.8065 | AUC=0.7384\n","\n","Training fold 4 for heat graph\n","Fold 4: Acc=0.7444 | Prec=0.7580 | Rec=0.7933 | F1=0.7752 | Loss=0.7146 | AUC=0.8006\n","\n","Training fold 5 for heat graph\n","Fold 5: Acc=0.7222 | Prec=0.7301 | Rec=0.7933 | F1=0.7604 | Loss=1.1033 | AUC=0.7419\n","\n","Training fold 6 for heat graph\n","Fold 6: Acc=0.7000 | Prec=0.7717 | Rec=0.6533 | F1=0.7076 | Loss=0.8784 | AUC=0.7612\n","\n","Training fold 7 for heat graph\n","Fold 7: Acc=0.7222 | Prec=0.7551 | Rec=0.7400 | F1=0.7475 | Loss=0.8253 | AUC=0.7894\n","\n","Training fold 8 for heat graph\n","Fold 8: Acc=0.7593 | Prec=0.7742 | Rec=0.8000 | F1=0.7869 | Loss=0.6878 | AUC=0.7939\n","\n","Training fold 9 for heat graph\n","Fold 9: Acc=0.6667 | Prec=0.7206 | Rec=0.6533 | F1=0.6853 | Loss=1.0380 | AUC=0.7195\n","\n","Training fold 10 for heat graph\n","Fold 10: Acc=0.7222 | Prec=0.7389 | Rec=0.7733 | F1=0.7557 | Loss=0.8175 | AUC=0.7816\n","\n","Training fold 11 for heat graph\n","Fold 11: Acc=0.7222 | Prec=0.7698 | Rec=0.7133 | F1=0.7405 | Loss=0.7581 | AUC=0.7906\n","\n","Training fold 12 for heat graph\n","Fold 12: Acc=0.7148 | Prec=0.7552 | Rec=0.7200 | F1=0.7372 | Loss=0.7102 | AUC=0.7917\n","\n","Training fold 13 for heat graph\n","Fold 13: Acc=0.7519 | Prec=0.7515 | Rec=0.8267 | F1=0.7873 | Loss=0.8030 | AUC=0.7806\n","\n","Training fold 14 for heat graph\n","Fold 14: Acc=0.6556 | Prec=0.7143 | Rec=0.6333 | F1=0.6714 | Loss=0.9626 | AUC=0.7408\n","\n","Training fold 15 for heat graph\n","Fold 15: Acc=0.7593 | Prec=0.7707 | Rec=0.8067 | F1=0.7883 | Loss=0.7208 | AUC=0.8076\n","\n","Training fold 16 for heat graph\n","Fold 16: Acc=0.7741 | Prec=0.7947 | Rec=0.8000 | F1=0.7973 | Loss=0.8000 | AUC=0.7979\n","\n","Training fold 17 for heat graph\n","Fold 17: Acc=0.7074 | Prec=0.7290 | Rec=0.7533 | F1=0.7410 | Loss=0.8662 | AUC=0.7589\n","\n","Training fold 18 for heat graph\n","Fold 18: Acc=0.7185 | Prec=0.7434 | Rec=0.7533 | F1=0.7483 | Loss=0.7354 | AUC=0.7877\n","\n","Training fold 19 for heat graph\n","Fold 19: Acc=0.7185 | Prec=0.7229 | Rec=0.8000 | F1=0.7595 | Loss=0.9779 | AUC=0.7314\n","\n","Training fold 20 for heat graph\n","Fold 20: Acc=0.6741 | Prec=0.6962 | Rec=0.7333 | F1=0.7143 | Loss=0.8108 | AUC=0.7431\n","\n","==== HEAT Graph 20-Fold Average Results ====\n","Accuracy: 0.7185 ± 0.0306\n","Precision: 0.7461 ± 0.0245\n","Recall: 0.7483 ± 0.0532\n","F1 Score: 0.7463 ± 0.0331\n","Cross-Entropy Loss: 0.8269 ± 0.1112\n","AUC: 0.7705 ± 0.0260\n","\n","\n","===== Running 20-Fold CV for PPR Graph =====\n","\n","Training fold 1 for ppr graph\n","Fold 1: Acc=0.7630 | Prec=0.7867 | Rec=0.7867 | F1=0.7867 | Loss=0.6963 | AUC=0.8077\n","\n","Training fold 2 for ppr graph\n","Fold 2: Acc=0.7333 | Prec=0.7600 | Rec=0.7600 | F1=0.7600 | Loss=0.7569 | AUC=0.7676\n","\n","Training fold 3 for ppr graph\n","Fold 3: Acc=0.7000 | Prec=0.7447 | Rec=0.7000 | F1=0.7216 | Loss=0.7605 | AUC=0.7562\n","\n","Training fold 4 for ppr graph\n","Fold 4: Acc=0.7593 | Prec=0.7852 | Rec=0.7800 | F1=0.7826 | Loss=0.6813 | AUC=0.8126\n","\n","Training fold 5 for ppr graph\n","Fold 5: Acc=0.7259 | Prec=0.7468 | Rec=0.7667 | F1=0.7566 | Loss=1.1267 | AUC=0.7366\n","\n","Training fold 6 for ppr graph\n","Fold 6: Acc=0.7037 | Prec=0.7778 | Rec=0.6533 | F1=0.7101 | Loss=0.8626 | AUC=0.7668\n","\n","Training fold 7 for ppr graph\n","Fold 7: Acc=0.7222 | Prec=0.7698 | Rec=0.7133 | F1=0.7405 | Loss=0.8005 | AUC=0.7922\n","\n","Training fold 8 for ppr graph\n","Fold 8: Acc=0.7519 | Prec=0.7345 | Rec=0.8667 | F1=0.7951 | Loss=0.6891 | AUC=0.7989\n","\n","Training fold 9 for ppr graph\n","Fold 9: Acc=0.6778 | Prec=0.7299 | Rec=0.6667 | F1=0.6969 | Loss=0.9940 | AUC=0.7337\n","\n","Training fold 10 for ppr graph\n","Fold 10: Acc=0.7185 | Prec=0.7176 | Rec=0.8133 | F1=0.7625 | Loss=0.7799 | AUC=0.7784\n","\n","Training fold 11 for ppr graph\n","Fold 11: Acc=0.7222 | Prec=0.7778 | Rec=0.7000 | F1=0.7368 | Loss=0.7535 | AUC=0.7943\n","\n","Training fold 12 for ppr graph\n","Fold 12: Acc=0.7185 | Prec=0.7643 | Rec=0.7133 | F1=0.7379 | Loss=0.7342 | AUC=0.7859\n","\n","Training fold 13 for ppr graph\n","Fold 13: Acc=0.7630 | Prec=0.7529 | Rec=0.8533 | F1=0.8000 | Loss=0.8292 | AUC=0.7767\n","\n","Training fold 14 for ppr graph\n","Fold 14: Acc=0.6593 | Prec=0.7164 | Rec=0.6400 | F1=0.6761 | Loss=0.9578 | AUC=0.7387\n","\n","Training fold 15 for ppr graph\n","Fold 15: Acc=0.7519 | Prec=0.7986 | Rec=0.7400 | F1=0.7682 | Loss=0.7523 | AUC=0.8081\n","\n","Training fold 16 for ppr graph\n","Fold 16: Acc=0.7852 | Prec=0.7771 | Rec=0.8600 | F1=0.8165 | Loss=0.8162 | AUC=0.7896\n","\n","Training fold 17 for ppr graph\n","Fold 17: Acc=0.7185 | Prec=0.7372 | Rec=0.7667 | F1=0.7516 | Loss=0.8314 | AUC=0.7684\n","\n","Training fold 18 for ppr graph\n","Fold 18: Acc=0.6963 | Prec=0.7267 | Rec=0.7267 | F1=0.7267 | Loss=0.8018 | AUC=0.7696\n","\n","Training fold 19 for ppr graph\n","Fold 19: Acc=0.6926 | Prec=0.7161 | Rec=0.7400 | F1=0.7279 | Loss=0.9244 | AUC=0.7269\n","\n","Training fold 20 for ppr graph\n","Fold 20: Acc=0.6963 | Prec=0.7048 | Rec=0.7800 | F1=0.7405 | Loss=0.7839 | AUC=0.7633\n","\n","==== PPR Graph 20-Fold Average Results ====\n","Accuracy: 0.7230 ± 0.0313\n","Precision: 0.7512 ± 0.0271\n","Recall: 0.7513 ± 0.0636\n","F1 Score: 0.7497 ± 0.0348\n","Cross-Entropy Loss: 0.8166 ± 0.1085\n","AUC: 0.7736 ± 0.0251\n"]}]},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","\n","for i in range(len(all_fpr)):\n","    plt.plot(all_fpr[i], all_tpr[i], alpha=0.3, label=f\"Fold {i+1} AUC = {all_auc[i]:.2f}\")\n","\n","fpr_avg, tpr_avg, _ = roc_curve(all_y_true, all_y_proba)\n","auc_avg = roc_auc_score(all_y_true, all_y_proba)\n","plt.plot(fpr_avg, tpr_avg, color='blue', lw=2, label=f\"Mean ROC (AUC = {auc_avg:.2f})\")\n","\n","plt.plot([0, 1], [0, 1], 'k--', label=\"Chance\")\n","\n","plt.xlabel(\"False Positive Rate\", fontsize=14)\n","plt.ylabel(\"True Positive Rate\", fontsize=14)\n","plt.title(\"ROC Curve Across 20 Folds (GDC-Chebconv)\", fontsize=16)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","plt.legend(loc=\"lower right\", fontsize=9)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Mgqnet2C_QDO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When alpha = 0"],"metadata":{"id":"5MpUOwVyVmXE"}},{"cell_type":"markdown","source":["===== Running 20-Fold CV for NONE Graph =====\n","\n","Training fold 1 for none graph\n","Fold 1: Acc=0.6444 | Prec=0.6849 | Rec=0.6667 | F1=0.6757 | Loss=1.0262\n","\n","Training fold 2 for none graph\n","Fold 2: Acc=0.7630 | Prec=0.7756 | Rec=0.8067 | F1=0.7908 | Loss=0.5848\n","\n","Training fold 3 for none graph\n","Fold 3: Acc=0.6630 | Prec=0.7323 | Rec=0.6200 | F1=0.6715 | Loss=1.0431\n","\n","Training fold 4 for none graph\n","Fold 4: Acc=0.7148 | Prec=0.7355 | Rec=0.7600 | F1=0.7475 | Loss=1.2836\n","\n","Training fold 5 for none graph\n","Fold 5: Acc=0.7296 | Prec=0.7225 | Rec=0.8333 | F1=0.7740 | Loss=2.0795\n","\n","Training fold 6 for none graph\n","Fold 6: Acc=0.6889 | Prec=0.7845 | Rec=0.6067 | F1=0.6842 | Loss=0.9347\n","\n","Training fold 7 for none graph\n","Fold 7: Acc=0.7148 | Prec=0.7920 | Rec=0.6600 | F1=0.7200 | Loss=1.0443\n","\n","Training fold 8 for none graph\n","Fold 8: Acc=0.7630 | Prec=0.7500 | Rec=0.8600 | F1=0.8012 | Loss=0.7468\n","\n","Training fold 9 for none graph\n","Fold 9: Acc=0.6630 | Prec=0.7323 | Rec=0.6200 | F1=0.6715 | Loss=1.2105\n","\n","Training fold 10 for none graph\n","Fold 10: Acc=0.7185 | Prec=0.7229 | Rec=0.8000 | F1=0.7595 | Loss=0.9980\n","\n","Training fold 11 for none graph\n","Fold 11: Acc=0.7259 | Prec=0.7533 | Rec=0.7533 | F1=0.7533 | Loss=1.0229\n","\n","Training fold 12 for none graph\n","Fold 12: Acc=0.7259 | Prec=0.7209 | Rec=0.8267 | F1=0.7702 | Loss=0.9860\n","\n","Training fold 13 for none graph\n","Fold 13: Acc=0.7556 | Prec=0.7283 | Rec=0.8933 | F1=0.8024 | Loss=1.0285\n","\n","Training fold 14 for none graph\n","Fold 14: Acc=0.6741 | Prec=0.7719 | Rec=0.5867 | F1=0.6667 | Loss=1.1702\n","\n","Training fold 15 for none graph\n","Fold 15: Acc=0.7370 | Prec=0.7423 | Rec=0.8067 | F1=0.7732 | Loss=1.0418\n","\n","Training fold 16 for none graph\n","Fold 16: Acc=0.7296 | Prec=0.7810 | Rec=0.7133 | F1=0.7456 | Loss=0.8196\n","\n","Training fold 17 for none graph\n","Fold 17: Acc=0.7333 | Prec=0.7468 | Rec=0.7867 | F1=0.7662 | Loss=0.7774\n","\n","Training fold 18 for none graph\n","Fold 18: Acc=0.7333 | Prec=0.7600 | Rec=0.7600 | F1=0.7600 | Loss=1.2302\n","\n","Training fold 19 for none graph\n","Fold 19: Acc=0.6741 | Prec=0.6867 | Rec=0.7600 | F1=0.7215 | Loss=1.1280\n","\n","Training fold 20 for none graph\n","Fold 20: Acc=0.6815 | Prec=0.7254 | Rec=0.6867 | F1=0.7055 | Loss=0.7750\n","\n","==== NONE Graph 20-Fold Average Results ====\n","Avg Acc=0.7117 | Avg Prec=0.7425 | Avg Rec=0.7403 | Avg F1=0.7380 | Avg Loss=1.0466\n","\n","\n","===== Running 20-Fold CV for HEAT Graph =====\n","\n","Training fold 1 for heat graph\n","Fold 1: Acc=0.7444 | Prec=0.7793 | Rec=0.7533 | F1=0.7661 | Loss=0.6634\n","\n","Training fold 2 for heat graph\n","Fold 2: Acc=0.7148 | Prec=0.7355 | Rec=0.7600 | F1=0.7475 | Loss=0.7208\n","\n","Training fold 3 for heat graph\n","Fold 3: Acc=0.6926 | Prec=0.7343 | Rec=0.7000 | F1=0.7167 | Loss=0.7711\n","\n","Training fold 4 for heat graph\n","Fold 4: Acc=0.7519 | Prec=0.7862 | Rec=0.7600 | F1=0.7729 | Loss=0.6621\n","\n","Training fold 5 for heat graph\n","Fold 5: Acc=0.7296 | Prec=0.7333 | Rec=0.8067 | F1=0.7683 | Loss=1.0293\n","\n","Training fold 6 for heat graph\n","Fold 6: Acc=0.7037 | Prec=0.7652 | Rec=0.6733 | F1=0.7163 | Loss=0.7929\n","\n","Training fold 7 for heat graph\n","Fold 7: Acc=0.7074 | Prec=0.7483 | Rec=0.7133 | F1=0.7304 | Loss=0.7919\n","\n","Training fold 8 for heat graph\n","Fold 8: Acc=0.7667 | Prec=0.7605 | Rec=0.8467 | F1=0.8013 | Loss=0.6479\n","\n","Training fold 9 for heat graph\n","Fold 9: Acc=0.6926 | Prec=0.7597 | Rec=0.6533 | F1=0.7025 | Loss=0.9527\n","\n","Training fold 10 for heat graph\n","Fold 10: Acc=0.7333 | Prec=0.7378 | Rec=0.8067 | F1=0.7707 | Loss=0.7733\n","\n","Training fold 11 for heat graph\n","Fold 11: Acc=0.7185 | Prec=0.7284 | Rec=0.7867 | F1=0.7564 | Loss=0.6970\n","\n","Training fold 12 for heat graph\n","Fold 12: Acc=0.7556 | Prec=0.7658 | Rec=0.8067 | F1=0.7857 | Loss=0.6952\n","\n","Training fold 13 for heat graph\n","Fold 13: Acc=0.7148 | Prec=0.7325 | Rec=0.7667 | F1=0.7492 | Loss=0.8044\n","\n","Training fold 14 for heat graph\n","Fold 14: Acc=0.6630 | Prec=0.7092 | Rec=0.6667 | F1=0.6873 | Loss=0.9734\n","\n","Training fold 15 for heat graph\n","Fold 15: Acc=0.7741 | Prec=0.7947 | Rec=0.8000 | F1=0.7973 | Loss=0.6749\n","\n","Training fold 16 for heat graph\n","Fold 16: Acc=0.7815 | Prec=0.7862 | Rec=0.8333 | F1=0.8091 | Loss=0.7412\n","\n","Training fold 17 for heat graph\n","Fold 17: Acc=0.6963 | Prec=0.7237 | Rec=0.7333 | F1=0.7285 | Loss=0.8609\n","\n","Training fold 18 for heat graph\n","Fold 18: Acc=0.7111 | Prec=0.7500 | Rec=0.7200 | F1=0.7347 | Loss=0.7224\n","\n","Training fold 19 for heat graph\n","Fold 19: Acc=0.7111 | Prec=0.7195 | Rec=0.7867 | F1=0.7516 | Loss=0.9156\n","\n","Training fold 20 for heat graph\n","Fold 20: Acc=0.7074 | Prec=0.7178 | Rec=0.7800 | F1=0.7476 | Loss=0.7517\n","\n","==== HEAT Graph 20-Fold Average Results ====\n","Avg Acc=0.7235 | Avg Prec=0.7484 | Avg Rec=0.7577 | Avg F1=0.7520 | Avg Loss=0.7821\n","\n","\n","===== Running 20-Fold CV for PPR Graph =====\n","\n","Training fold 1 for ppr graph\n","Fold 1: Acc=0.7407 | Prec=0.7667 | Rec=0.7667 | F1=0.7667 | Loss=0.6939\n","\n","Training fold 2 for ppr graph\n","Fold 2: Acc=0.7185 | Prec=0.7500 | Rec=0.7400 | F1=0.7450 | Loss=0.7584\n","\n","Training fold 3 for ppr graph\n","Fold 3: Acc=0.6889 | Prec=0.7200 | Rec=0.7200 | F1=0.7200 | Loss=0.7658\n","\n","Training fold 4 for ppr graph\n","Fold 4: Acc=0.7630 | Prec=0.7945 | Rec=0.7733 | F1=0.7838 | Loss=0.6519\n","\n","Training fold 5 for ppr graph\n","Fold 5: Acc=0.7370 | Prec=0.7310 | Rec=0.8333 | F1=0.7788 | Loss=1.0700\n","\n","Training fold 6 for ppr graph\n","Fold 6: Acc=0.6704 | Prec=0.7521 | Rec=0.6067 | F1=0.6716 | Loss=0.8375\n","\n","Training fold 7 for ppr graph\n","Fold 7: Acc=0.7074 | Prec=0.7554 | Rec=0.7000 | F1=0.7266 | Loss=0.7799\n","\n","Training fold 8 for ppr graph\n","Fold 8: Acc=0.7630 | Prec=0.7560 | Rec=0.8467 | F1=0.7987 | Loss=0.6454\n","\n","Training fold 9 for ppr graph\n","Fold 9: Acc=0.6481 | Prec=0.6923 | Rec=0.6600 | F1=0.6758 | Loss=0.9620\n","\n","Training fold 10 for ppr graph\n","Fold 10: Acc=0.7222 | Prec=0.7517 | Rec=0.7467 | F1=0.7492 | Loss=0.7410\n","\n","Training fold 11 for ppr graph\n","Fold 11: Acc=0.7000 | Prec=0.7518 | Rec=0.6867 | F1=0.7178 | Loss=0.7213\n","\n","Training fold 12 for ppr graph\n","Fold 12: Acc=0.7222 | Prec=0.7778 | Rec=0.7000 | F1=0.7368 | Loss=0.7088\n","\n","Training fold 13 for ppr graph\n","Fold 13: Acc=0.7407 | Prec=0.7410 | Rec=0.8200 | F1=0.7785 | Loss=0.7892\n","\n","Training fold 14 for ppr graph\n","Fold 14: Acc=0.6630 | Prec=0.7092 | Rec=0.6667 | F1=0.6873 | Loss=0.9339\n","\n","Training fold 15 for ppr graph\n","Fold 15: Acc=0.7741 | Prec=0.7908 | Rec=0.8067 | F1=0.7987 | Loss=0.6581\n","\n","Training fold 16 for ppr graph\n","Fold 16: Acc=0.7889 | Prec=0.8000 | Rec=0.8267 | F1=0.8131 | Loss=0.7573\n","\n","Training fold 17 for ppr graph\n","Fold 17: Acc=0.6852 | Prec=0.7211 | Rec=0.7067 | F1=0.7138 | Loss=0.8338\n","\n","Training fold 18 for ppr graph\n","Fold 18: Acc=0.7000 | Prec=0.7315 | Rec=0.7267 | F1=0.7291 | Loss=0.7684\n","\n","Training fold 19 for ppr graph\n","Fold 19: Acc=0.6926 | Prec=0.7055 | Rec=0.7667 | F1=0.7348 | Loss=0.8800\n","\n","Training fold 20 for ppr graph\n","Fold 20: Acc=0.6963 | Prec=0.7267 | Rec=0.7267 | F1=0.7267 | Loss=0.7200\n","\n","==== PPR Graph 20-Fold Average Results ====\n","Avg Acc=0.7161 | Avg Prec=0.7463 | Avg Rec=0.7413 | Avg F1=0.7426 | Avg Loss=0.7838"],"metadata":{"id":"CEKg_XsEVi0i"}},{"cell_type":"code","source":["# results = {}\n","# for name, d in zip(['none', 'heat', 'ppr'], [data_none, data_heat, data_ppr]):\n","#     results[name] = train_eval(d, seeds=50)\n","\n","# for name, best_dict in results.items():\n","#     boots_series = sns.algorithms.bootstrap(best_dict['test_acc'], func=np.mean, n_boot=1000)\n","#     ci = np.max(np.abs(sns.utils.ci(boots_series, 95) - np.mean(best_dict['test_acc'])))\n","#     mean_acc = np.mean(best_dict['test_acc'])\n","#     print(f\"{name}: Mean accuracy: {100*mean_acc:.2f} ± {100*ci:.2f}%\")"],"metadata":{"id":"t0tDJnd--ZQu"},"execution_count":null,"outputs":[]}]}